import { useState, useRef, useCallback } from "react";

// å®šä¹‰å›è°ƒç±»å‹
type OnResultCallback = (
  text: string,
  duration: number,
  audioBlob: Blob | null
) => void;

export const useSpeechRecognition = (onResult: OnResultCallback) => {
  const [isRecording, setIsRecording] = useState(false);

  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const startTimeRef = useRef<number>(0);
  const isAbortedRef = useRef<boolean>(false); // æ–°å¢ï¼šç”¨äºæ ‡è®°æ˜¯å¦å–æ¶ˆ

  // å¼€å§‹å½•éŸ³
  const startListening = useCallback(async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);

      mediaRecorderRef.current = mediaRecorder;
      audioChunksRef.current = [];
      startTimeRef.current = Date.now();
      isAbortedRef.current = false; // é‡ç½®å–æ¶ˆæ ‡è®°

      mediaRecorder.ondataavailable = (event) => {
        if (event.data.size > 0) {
          audioChunksRef.current.push(event.data);
        }
      };

      mediaRecorder.onstop = () => {
        // ğŸ›‘ å…³é”®é€»è¾‘ï¼šå¦‚æœæ ‡è®°ä¸ºâ€œå–æ¶ˆâ€ï¼Œåˆ™ä»€ä¹ˆéƒ½ä¸åš
        if (isAbortedRef.current) {
          console.log("å½•éŸ³å·²å–æ¶ˆï¼Œä¸å‘é€");
          // åœæ­¢æ‰€æœ‰è½¨é“é‡Šæ”¾éº¦å…‹é£
          stream.getTracks().forEach((track) => track.stop());
          return;
        }

        // æ­£å¸¸ç»“æŸï¼šè®¡ç®—æ—¶é•¿å¹¶ç”Ÿæˆ Blob
        const duration = Math.round((Date.now() - startTimeRef.current) / 1000);
        const audioBlob = new Blob(audioChunksRef.current, {
          type: "audio/webm",
        });

        // å›è°ƒä¼ å‡ºæ•°æ®
        onResult("", duration < 1 ? 1 : duration, audioBlob);

        // åœæ­¢è½¨é“
        stream.getTracks().forEach((track) => track.stop());
      };

      mediaRecorder.start();
      setIsRecording(true);
    } catch (error) {
      console.error("æ— æ³•è®¿é—®éº¦å…‹é£:", error);
      alert("è¯·å…è®¸æµè§ˆå™¨è®¿é—®éº¦å…‹é£");
    }
  }, [onResult]);

  // æ­£å¸¸åœæ­¢ï¼ˆå‘é€ï¼‰
  const stopListening = useCallback(() => {
    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state !== "inactive"
    ) {
      isAbortedRef.current = false; // æ ‡è®°ä¸ºæ­£å¸¸ç»“æŸ
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  }, []);

  // å–æ¶ˆå½•éŸ³ï¼ˆä¸å‘é€ï¼‰
  const abortListening = useCallback(() => {
    if (
      mediaRecorderRef.current &&
      mediaRecorderRef.current.state !== "inactive"
    ) {
      isAbortedRef.current = true; // æ ‡è®°ä¸ºå–æ¶ˆ
      mediaRecorderRef.current.stop();
      setIsRecording(false);
    }
  }, []);

  return {
    isRecording,
    startListening, // å¯¹åº” InputArea çš„è°ƒç”¨
    stopListening, // å¯¹åº” InputArea çš„è°ƒç”¨
    abortListening, // å¯¹åº” InputArea çš„è°ƒç”¨
    hasMicrophoneAccess: true,
  };
};
